{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn\n",
    "- python 기반의 machine learning은 곧 scikit-learn으로 개발하는 것을 의미할 정도의 library\n",
    "- 가장 쉽고 효율적인 개발 library를 제공 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scikit-learn의 주요 모듈\n",
    "\n",
    "다음은 scikit-learn의 주요 모듈을 요약한 것이다. 언급된 모듈 외에도 많은 모듈이 있으나 자주 쓰이는 핵심 모듈 위주로 정리한 것이다.\n",
    "\n",
    "|분류    | 모듈명   | 설명   |\n",
    "|:------|:----|:----|\n",
    "| 예제 데이터   | sklearn.datasets  | scikit-learn에 내장되어 예제로 제공하는 데이터 세트  |\n",
    "| 피처처리    | sklearn.preprocessing  | 데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링등)  |\n",
    "| -  | sklearn.feature_selection | 알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공  |\n",
    "| - | sklearn.feature_extraction  | 텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨. 예를 들어 텍스트 데이터에서 Count Vectorizer나 TF-IDF Vectorizer 등을 생성하는 기능 제공. 텍스트 데이터의 feature 추출은 sklearn.feature_extraction.text 모듈에 이미지 데이터의 feature 추출은 sklearn.feature_extraction.image 모듈에 지원 API가 있음.  |\n",
    "| 피처 처리 & 차원 축소  | sklearn.decomposition   | 차원 축소와 관련한 알고리즘을 지원하는 모듈임. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능을 수행할 수 있음.   |\n",
    "| 데이터 분리, 검증 & 파라미터 튜닝 | sklearn.model_selection | 교차 검증을 위한 학습용/테스트용 분리, grid search로 최적 파라미터 추출 등의 API 제공  |\n",
    "| 평가    | sklearn.metrics   | 분류, 회귀, 클러스터링, 페어와이즈에 대한 다양한 성능 측정 방법 제공 |\n",
    "| ML 알고리즘    | sklearn.ensemble  | 앙상블 알고리즘 제공, 랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등을 제공 |\n",
    "|  -  | sklearn.linear_model  | 주로 선형 회귀, Ridge, Lasso 및 Logistic 등 회귀 관련 알고리즘을 지원. 또한 SGD(Stochastic Gradient Descent)관련 알고리즘도 제공   |\n",
    "|  -  | sklearn.naive_bayes  | 나이브 베이즈 알고리즘 제공. Gaussian NB, Multinomial NB 등. |\n",
    "| -  | sklearn.neighbors  | 최근접 이웃 알고리즘 제공. K-NN등  |\n",
    "| -   | sklearn.svm  | 서포트 벡터 머신 알고리즘 제공  |\n",
    "| -   | sklearn.tree  | 의사 결정 트리 알고리즘 제공  |\n",
    "| -   | sklearn.cluster  | 비지도 클러스터링 알고리즘 제공(K-Means, 계층형, DBSCAN 등)  |\n",
    "| 유틸리티   | sklearn.pipline  | feature 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning process\n",
    "\n",
    "![Machine_Learning_process](Machine_Learning_process.png)\n",
    "\n",
    "일반적으로 Machine Learning Model을 구축하는 주요 프로세스를 크게 3단계로 나누자면 다음과 같다.\n",
    "\n",
    "1) feature processing (feature의 EDA 뿐만아니라 가공, 변경, 추출을 수행)\n",
    "\n",
    "2) ML 알고리즘 학습/예측 수행\n",
    "\n",
    "3) Model 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-vaildation(교차검증)\n",
    "\n",
    "위에서 2번째 단계를 생각해 보자. 알고리즘을 학습시키는 `train data set`과 이에 대한 예측 성능을 평가하기 위한 별도의 `test data set`이 필요할 것이다. `하지만 이렇게 train data 와 test data로만 나누어주는 방법 역시 Overfitting에 취약한 약점을 가질 수 있다.` \n",
    "- Overfitting은 Model이 train data에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행하는 경우에는 예측 성능이 과도하게 떨어지는 것을 의미한다. `그런데 고정된 학습 데이터와 테스트 데이터로 평가를 하다 보면 테스트 데이터에만 Over fitting되는 학습 모델이 만들어져 다른 데이터가 들어올 경우에는 성능이 저하된다.` 이러한 문제점을 개선하기 위해 Cross-validation(교차검증)을 이용해 더 다양한 학습과 평가를 수행한다.\n",
    "\n",
    "#### ML(Machine Learning) 데이터에 기반합니다.\n",
    "- 그리고 데이터는 이상치, 분포도, 다양한 속성값, feature importance 등 여러 가지 ML에 영향을 미치는 요소를 가지고 있다. `특정 ML 알고리즘에서 최적으로 동작할 수 있도록 데이터를 선별해 학습한다면 실제 데이터 양식과는 많은 차이가 있을 것이고 결국 성능 저하로 이어질 것이다.` \n",
    "\n",
    "- Cross-validation(교차 검증)은 이러한 데이터 편중을 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것이다. `대부분의 ML 모델의 성능 평가는 교차 검증 기반으로 1차 평가를 한 뒤에 최종적으로 테스트 데이터 세트에 적용해 평가하는 프로세스`이다. \n",
    "\n",
    "- `결론적으로 ML에 사용되는 데이터 세트를 세분화해서 학습, 검증, 테스트 데이터로 나눌 수 있다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold Cross-validation(K-폴드 교차검증)\n",
    "- 가장 보편적인 교차 검증 기법으로 먼저 K개의 데이터 fold 세트를 만들어서 K번 만큼 각 폴드 세트에 학습과 검증 평가를 반복적으로 수행하는 방법이다. \n",
    "\n",
    "![K-fold Cross-validation](kfold.png)\n",
    "\n",
    "위의 그림같이 학습데이터 세트와 검증 데이터 세트를 점진적으로 변경하면서 마지막 K번째(위의 예시에서는 5번째)까지 학습과 검증을 수행하는 것이다. `각각의 검증 데이터에 대한 예측 평가를 구했으면 이를 평균해서 K-fold 평가 결과로 반영하면 된다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn에서는 K-fold Cross-validation Process를 구현하기 위해 KFold와 StratifiedKFold 클래스를 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 시도 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 29 개, label 1 : 29 개, label 2 : 26 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 5 개, label 2 : 9 개\n",
      "\n",
      "2번째 시도 교차 검증 정확도 : 0.9523809523809523, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 30 개, label 1 : 29 개, label 2 : 25 개\n",
      "검증데이터 - label 0 : 6 개, label 1 : 5 개, label 2 : 10 개\n",
      "\n",
      "3번째 시도 교차 검증 정확도 : 0.8571428571428571, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 29 개, label 1 : 26 개, label 2 : 29 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 8 개, label 2 : 6 개\n",
      "\n",
      "4번째 시도 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 24 개, label 1 : 28 개, label 2 : 32 개\n",
      "검증데이터 - label 0 : 12 개, label 1 : 6 개, label 2 : 3 개\n",
      "\n",
      "5번째 시도 교차 검증 정확도 : 0.9523809523809523, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 32 개, label 1 : 24 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 4 개, label 1 : 10 개, label 2 : 7 개\n",
      "\n",
      "\n",
      "검증 데이터 평균 정확도 : 0.9523809523809523\n",
      "\n",
      "테스트 데이터 정확도 : 0.9333333333333333\n",
      "테스트 데이터 - label 0 : 14 개, label 1 : 16 개, label 2 : 15 개\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=121)\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(features, label, random_state=121, test_size=0.3)\n",
    "\n",
    "# K-fold(k=5)를 지정해주고 그 후에 각 검증데이터의 평가값을 저장할 리스트 객체를 하나 만들어준다.\n",
    "kfold = KFold(n_splits=5, random_state=121, shuffle=True)\n",
    "cv_accuracy=[]\n",
    "\n",
    "n_iter=0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 row index를 array로 변환\n",
    "# for train_index, test_index for \n",
    "for train_idx, validation_idx in kfold.split(train_data):\n",
    "    X_train, X_test = train_data[train_idx], train_data[validation_idx]\n",
    "    y_train, y_test = train_label[train_idx], train_label[validation_idx]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복시 마다 정확도 측정\n",
    "    accuracy =  accuracy_score(y_test, pred)\n",
    "    \n",
    "    train_size = X_train.shape[0]\n",
    "    test_size =  X_test.shape[0]\n",
    "    \n",
    "    train_label1_size = sum(y_train==0)\n",
    "    train_label2_size = sum(y_train==1)\n",
    "    train_label3_size = sum(y_train==2)\n",
    "    \n",
    "    test_label1_size = sum(y_test==0)\n",
    "    test_label2_size = sum(y_test==1)\n",
    "    test_label3_size = sum(y_test==2)\n",
    "    \n",
    "    print(\"{}번째 시도 교차 검증 정확도 : {}, 학습 데이터 크기 : {},  검증용 데이터 크기 : {}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"학습데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(train_label1_size, train_label2_size, train_label3_size))\n",
    "    print(\"검증데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(test_label1_size, test_label2_size, test_label3_size))\n",
    "    print()\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print()\n",
    "print(\"검증 데이터 평균 정확도 : {}\".format(np.mean(cv_accuracy, axis=0)))\n",
    "\n",
    "test_pred=dt_clf.predict(test_data)\n",
    "test_accuracy=accuracy_score(test_label, test_pred)\n",
    "\n",
    "print()\n",
    "print(\"테스트 데이터 정확도 : {}\".format(test_accuracy))\n",
    "\n",
    "test_label1 = sum(test_label==0)\n",
    "test_label2 = sum(test_label==1)\n",
    "test_label3 = sum(test_label==2)\n",
    "\n",
    "print(\"테스트 데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(test_label1, test_label2, test_label3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified K Fold\n",
    "- `Stratified K-Fold는 imbalanced data(불균형한 분포도를 가진 레이블(클래스) 데이터 집합)을 위한 K-Fold 방식이다.` 불균형한 분포도를 가진 레이블(결정 클래스) 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 값의 분포가 한쪽으로 치우치는 것을 말한다. 예를 들어서 대출 사기 데이터같은 경우이다. 데이터 대부분은 정상 대출이지만 아주 작은 비율로 사기 대출의 데이터가 나타나질 것이다. 이런 상태에서 K-fold로 랜덤하게 학습 및 테스트 세트의 인덱스를 고르더라고 레이블 값인 0과 1의 비율을 제대로 반영하지 못하는 경우가 쉽게 발생한다. 즉, 레이블 값으로 1이 특정 개별 반복별 학습/테스트 데이터 세트에는 상대적으로 많이 들어 있고, 다른 반복 학습/테스트 데이터 세트에는 그렇지 못한 결과가 발생한다. `대츨 사기 레이블이 1인 레코드(대출사기 건)는 비록 건수는 작지만 알고리즘이 대출 사기를 예측하기 위한 중요한 피처 값을 가지고 있기 때문에 매우 중요한 데이터 세트이다.` 따라서 `원본 데이터와 유사한 대출 사기 레이블 값의 분포를 학습/테스트 세트에고 유지하는 게 매우 중요`하다. \n",
    "\n",
    "\n",
    "\n",
    "- `Stratified K-Fold는 이처럼 K-fold가 레이블 데이터 집합이 원본 데이터 집합의 레이블 분포를 학습 및 테스트 세트에 제대로 분배하지 못하는 경우의 문제를 해결해 준다!`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 시도 교차 검증 정확도 : 0.9047619047619048, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 28 개, label 1 : 28 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 7 개, label 2 : 7 개\n",
      "\n",
      "2번째 시도 교차 검증 정확도 : 0.9047619047619048, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 28 개, label 1 : 28 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 7 개, label 2 : 7 개\n",
      "\n",
      "3번째 시도 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 28 개, label 1 : 28 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 7 개, label 2 : 7 개\n",
      "\n",
      "4번째 시도 교차 검증 정확도 : 0.9523809523809523, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 28 개, label 1 : 28 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 7 개, label 2 : 7 개\n",
      "\n",
      "5번째 시도 교차 검증 정확도 : 0.9047619047619048, 학습 데이터 크기 : 84,  검증용 데이터 크기 : 21\n",
      "학습데이터 - label 0 : 28 개, label 1 : 28 개, label 2 : 28 개\n",
      "검증데이터 - label 0 : 7 개, label 1 : 7 개, label 2 : 7 개\n",
      "\n",
      "\n",
      "검증 데이터 평균 정확도 : 0.9333333333333333\n",
      "\n",
      "테스트 데이터 정확도 : 0.9555555555555556\n",
      "테스트 데이터 - label 0 : 15 개, label 1 : 15 개, label 2 : 15 개\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state=121)\n",
    "\n",
    "train_data, test_data, train_label, test_label = train_test_split(features, label, random_state=121, test_size=0.3, stratify=label)\n",
    "\n",
    "# K-fold(k=5)를 지정해주고 그 후에 각 검증데이터의 평가값을 저장할 리스트 객체를 하나 만들어준다.\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=121)\n",
    "cv_accuracy=[]\n",
    "\n",
    "n_iter=0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용, 검증용 테스트의 row index를 array로 변환\n",
    "# for train_index, test_index for \n",
    "for train_idx, validation_idx in skf.split(train_data, train_label):\n",
    "    X_train, X_test = train_data[train_idx], train_data[validation_idx]\n",
    "    y_train, y_test = train_label[train_idx], train_label[validation_idx]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter += 1\n",
    "    \n",
    "    # 반복시 마다 정확도 측정\n",
    "    accuracy =  accuracy_score(y_test, pred)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size =  X_test.shape[0]\n",
    "    \n",
    "    train_label1_size = sum(y_train==0)\n",
    "    train_label2_size = sum(y_train==1)\n",
    "    train_label3_size = sum(y_train==2)\n",
    "    \n",
    "    test_label1_size = sum(y_test==0)\n",
    "    test_label2_size = sum(y_test==1)\n",
    "    test_label3_size = sum(y_test==2)\n",
    "    \n",
    "    print(\"{}번째 시도 교차 검증 정확도 : {}, 학습 데이터 크기 : {},  검증용 데이터 크기 : {}\".format(n_iter, accuracy, train_size, test_size))\n",
    "    print(\"학습데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(train_label1_size, train_label2_size, train_label3_size))\n",
    "    print(\"검증데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(test_label1_size, test_label2_size, test_label3_size))\n",
    "    print()\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print()\n",
    "print(\"검증 데이터 평균 정확도 : {}\".format(np.mean(cv_accuracy, axis=0)))\n",
    "\n",
    "test_pred=dt_clf.predict(test_data)\n",
    "test_accuracy=accuracy_score(test_label, test_pred)\n",
    "\n",
    "print()\n",
    "print(\"테스트 데이터 정확도 : {}\".format(test_accuracy))\n",
    "\n",
    "test_label1 = sum(test_label==0)\n",
    "test_label2 = sum(test_label==1)\n",
    "test_label3 = sum(test_label==2)\n",
    "\n",
    "print(\"테스트 데이터 - label 0 : {} 개, label 1 : {} 개, label 2 : {} 개\".format(test_label1, test_label2, test_label3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위에서 Stratified K-fold를 이용하지 않고 K-fold만을 사용하였을 때에는 각 클래스별 비율을 고려하지 않은채로 교차검증의 여부에만 초점을 두었다면 아래의 경우는 학습될 때와 검증할 때 그리고 성능을 평가하기 위한 예측 할 경우 모두 동일한 클래스 비율을 가지고 있는채로 훈련을 시켜 예측을 하였더니 더 좋은 성능이 나왔다!\n",
    "\n",
    "- `사실, 일반적으로 Classification(분류)에서의 교차 검증은 K-Fold가 아니라 Stratified K-Fold로 분할돼야 한다. Regression(회귀)에서는 Stratified K-Fold가 지원되지 않는다. 그것은 너무나도 당연한 것이다. 왜냐하면 회귀의 결정값(출력값 또는 종속변수 값)은 이산값 형태의 레이블이 아닌 연속형의 자료형태이므로 결정값별로 분포를 정하는 것은 의미가 없기 때문이다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold vs Stratified K-Fold\n",
    "\n",
    "| -   | K-Fold    | Stratified K-Fold   |\n",
    "|:------|:----|:----|\n",
    "| 장점   | Overfitting을 막기 위해 학습되는 데이터의 다양성을 높여준다.  |\n",
    "| 단점   | 클래스(label)별 분포를 고려해주지않는다.  | None  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross_val_score()\n",
    "\n",
    "- K-Fold로 데이터를 학습하고 예측하는 코드는 보통 다음과 같은 일련의 작업을 거쳐야 한다.\n",
    "    \n",
    "    - 1) Fold 세트를 설정하고\n",
    "    - 2) for문에서 반복으로 학습 및 검증 데이터의 인덱스를 추출한 뒤\n",
    "    - 3) 반복적으로 학습과 예측을 수행하고 예측 성능을 반환했다.\n",
    "\n",
    "\n",
    "- 이러한 교차 검증을 보다 간편하게 할 수 있는 API를 제공한다.\n",
    "```bash\n",
    "cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n",
    "```\n",
    "\n",
    "    - estimator는 scikit-learn의 Classifier 또는 Regressor를 의미한다.`(Classifier가 입력되면 Stratified K-Fold 방식으로 분할)` \n",
    "    - X : feature data\n",
    "    - y : label(class)\n",
    "    - scoring : metric\n",
    "    - cv : 교차 검증 fold 수\n",
    " \n",
    "cross_val_score() 수행 후 반환 값은 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환한다. API 내부에서 Estimator를 학습(fit), 예측(predict), 평가(evaluation) 시켜주므로 간단하게 교차 검증을 할 수 있다. `비슷한 API로 cross_validate()가 있다. cross_val_score()는 단 한나의 평가 지표만 가능하지만 cross_validate()는 여러 개의 평가 지표를 반환할 수 있다. 또한 학습 데이터에 대한 성능 평가 지표와 수행 시간도 같이 제공한다. 그러나 보통 cross_val_score() 하나로도 대부분의 경우 쉽게 사용한다.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에\n",
    "\n",
    "하이퍼 파라미터를 조절하여 ML 알고리즘의 예측 성능을 개선할 수 있다. \n",
    "\n",
    "- scikit-learn은 GridSearchCV API를 이용해 Classifier나 Regressor와 같은 알고리즘에 사용되는 하이퍼 파라미터를 순차적으로 입력하면서 편리하게 최적의 파라미터를 도출할 수 있는 방안을 제공한다. \n",
    "\n",
    "\n",
    "- 사용자가 튜닝하고자 하는 여러 종류의 하이퍼 파라미터를 다양하게 테스트하면서 최적의 파라미터를 편리하게 찾게 해주지만 동시에 순차적으로 파라미터를 테스트하므로 수행시간이 상대적으로 오래 걸리는 것에 유념해야한다. \n",
    "\n",
    "\n",
    "- 파라미터의 조합의 갯수 * cv의 횟수 만큼 학습/평가가 이뤄진다.\n",
    "``` bash\n",
    "GridSearchCV(estimator, param_grid, scoring,  cv, refit)\n",
    "```\n",
    "    - extimator : classifier, regressor, pipline\n",
    "    - param_grid : 딕셔너리가 주어진다.(파라미터 명을 key 값으로 파라미터 값들을 value로 갖는) \n",
    "    - scoring : evaluation metric(보통은 scikit-learn의 성능 평가 지표를 지정하는 문자열로 지정하나 별도의 성능 평가 지표 함수도 지정할 수 있다.)\n",
    "    - cv : 교차 검증을 위해 분할 되는 학습/검증 세트의 개수를 지정한다.\n",
    "    - `refit : default가 True이며 True로 생성 시 가장 최적의 하이퍼 파라미터를 찾은 뒤 입력된 estimator 객체를 해당 파라미터로 재학습 시킨다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/heungbaelee/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.666667                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.666667                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.933333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.933333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.942857                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.942857                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0           0.666667           0.657143           0.676471  \n",
       "1           0.666667           0.657143           0.676471  \n",
       "2           0.944444           0.914286           0.941176  \n",
       "3           0.944444           0.914286           0.941176  \n",
       "4           0.972222           0.914286           0.941176  \n",
       "5           0.972222           0.914286           0.941176  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "iris=load_iris()\n",
    "X_train, X_test, y_train, y_test =  train_test_split(iris.data, iris.target, random_state=121, test_size=0.3)\n",
    "\n",
    "dtree=DecisionTreeClassifier()\n",
    "\n",
    "parameter = {\"max_depth\":[1, 2, 3], \"min_samples_split\" : [2, 3]}\n",
    "\n",
    "grid_dtree=GridSearchCV(dtree, param_grid=parameter, scoring=\"accuracy\", cv=3, refit=True, verbose=False)\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\n",
    "score_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "score_df[[\"params\", \"mean_test_score\", \"rank_test_score\", \"split0_test_score\", \"split1_test_score\", \"split2_test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    `GridSearchCV 객체의 fit() 을 수행하면 최고 성능을 나타낸 하이퍼 파라미터의 값과 그때의 평가 결과 값이 각각 best_params_, best_score_ 속성에 기록된다. 또한 refit=True로 default인 상태로 수행했다면 우리는 best_estimator_ 속성을 이용해 최적의 파라미터로 학습되어 있는 모델을 바로 사용할 수 있다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최적 파라미터 : {'max_depth': 3, 'min_samples_split': 2}\n",
      "GridSearchCV 최고 성능 : 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"GridSearchCV 최적 파라미터 : {}\".format(grid_dtree.best_params_))\n",
    "print(\"GridSearchCV 최고 성능 : {}\".format(grid_dtree.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "estimator = grid_dtree.best_estimator_\n",
    "\n",
    "pred = estimator.predict(X_test)\n",
    "print(\"테스트 데이터 세트 정확도 : {0:.4f}\".format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
